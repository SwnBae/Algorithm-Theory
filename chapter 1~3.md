## Insertion Sort (삽입정렬)
for j = 2 to length[A]
 do key <- A[j]
 //insert A[j] to sorted sequence A[1..j-1]
 i <- j-1
 while i >0 and A[i]>key
 do A[i+1] <- A[i] //move A[i] one position right
 i<- i-1
 A[i+1] -< key

#### Worst case
• Reverse sorted list
• O(n²)
#### Best Case
• Sorted input
• O(n)

작은 n에 대해선 대부분 빠르지만, 큰 n에 대해선 느리다.


## Merge sort (합병정렬)
if p < r
then q <- |(p+r)/2|
 MERGE-SORT(A, p, q)
 MERGE-SORT(A, q+1, r)
 MERGE(A, p, q, r)

 T(n) = Θ(1) if n<=c
        aT(n/b)+D(n)+C(n)

a: number of subproblems
n/b: size of each subproblem
D(n): cost of divide operation = Θ(1)
C(n): cost of combination operation = Θ(n)

#### 1. 병합 정렬의 트리 구조
병합 정렬의 핵심은 배열을 계속해서 절반으로 분할하고, 분할된 배열을 다시 병합하는 과정입니다. 이를 트리 구조로 표현하면:

트리의 높이(log₂n + 1): 배열을 반으로 나누는 횟수는 log₂n입니다. 그러나, 마지막 병합 단계까지 고려하면, 전체 트리의 높이는 log₂n + 1이 됩니다.
예를 들어, 배열의 크기가 8이라면, log₂8 = 3번의 분할이 이루어지며, 마지막 병합까지 포함하면 높이는 4가 됩니다.

log₂n + 1은 트리의 높이(분할과 병합의 총 단계)

#### 2. 병합 단계에서의 연산 비용
병합 정렬에서는 각 단계에서 배열의 요소들을 비교하며 병합을 수행합니다. 이 과정에서 병합 단계의 연산 비용은 배열의 크기 n에 비례합니다. 즉, 각 병합 단계에서 **O(n)**의 시간이 소요됩니다.
##### 각 병합 단계마다 배열의 모든 요소가 비교에 참여합니다. 따라서, 병합 정렬의 각 병합 단계에서의 비교 횟수는 항상 **O(n)**입니다.



## Asymptotic Analysis (n → ∞)
#### 가장 높은 차수 항만 고려

#### 계수와 낮은 차수 항은 무시
 알고리즘의 실행 시간이 an² + bn + c로 표현된다면, 점근 표기법에서는 n²가 가장 큰 차수 항이므로, 이 알고리즘의 실행 시간의 성장률은 **O(n²)**로 표현됩니다. 여기서 a, b, c와 같은 계수나 상수항은 무시됩니다.


## Big O: Upper bound (Big O 표기법)

#### O(g(n))={f(n)∣존재하는 양의 상수 c와 n0 가 있어서 0≤f(n)≤c⋅g(n) for all n≥n0}
 f(n)이 g(n)에 비해 "느리게 성장하는" 함수들의 모임

##### Ex)
f(n)=2n^2+3n+1 , g(n) = n^2
 if c=3?
2n^2+3n+1 ≤ 3⋅n^2 (for sufficiently large n)
 f(n) = O(n^2)

#### 상한이 성립하려면, 다음과 같은 조건을 만족하는 **양의 상수 𝑐**와 **자연수 𝑛0**를 찾아야 합니다: f(n)≤c⋅g(n)

### 알고리즘의 실행 시간에 대한 최악의 경우를 이해하고 예측할 수 있는 유용한 도구


## Omega: Lower bound (Ω 표기법)

#### Ω(g(n))={f(n)∣존재하는 양의 상수 c와 n0가 있어서 0≤c⋅g(n)≤f(n) for all n>n0}
하한(Bound): 함수 f(n)의 값이 함수 𝑔(𝑛)의 일정한 배수 이상으로 제한된다는 것을 의미

##### 안정성 보장 : 알고리즘의 성능이 최소한 이 정도는 유지된다는 보장을 제공
##### 최소 성능 평가: 하한을 통해 특정 알고리즘이 최악의 경우 성능을 어떻게 보장하는지를 알 수 있음

##### Ex)
f(n)=3n^2+2n+1 , g(n) = n^2
 if c=2?
2n^2 ≤ 3n^2+2n+1 (for sufficiently large n)
f(n) = Ω(n^2)


## Theta: Upper and lower bound (Θ (Theta) 표기법)

#### Θ(g(n))={f(n)∣존재하는 양의 상수 c1​ ,c2​ 와 n0​ 가 있어서 c1⋅g(n) ≤ f(n) ≤ c2​ ⋅g(n) for all n>n0​}

##### 정확한 성능 예측: 알고리즘의 실행 시간이 𝑔(𝑛)와 비슷하게 증가한다는 것을 보장하므로, 알고리즘의 성능을 더 정확하게 예측

##### Ex)
f(n)=5n^2+3n+2 , g(n) = n^2
상한: 5𝑛^2+3𝑛+2 ≤ 6𝑛^2(예를 들어 𝑐2=6및 𝑛0=1일 때)
하한: 5𝑛^2+3𝑛+2 ≥ 4𝑛^2(예를 들어 𝑐1=4및 𝑛0=1일 때)
###### f(n)=Θ(n^2)

#### Merge Sort의 실행 시간을 분석할 때 Θ 표기법을 사용하는 것이 왜 더 나은지?

Big O (O): 알고리즘의 실행 시간이 특정 함수에 대해 **상한(Upper Bound)**을 제공하는 표현입니다. 즉, 알고리즘의 최악의 경우 성능에 대한 제한을 나타내며, **"이 알고리즘의 실행 시간은 이보다 크지 않다"**는 정보를 제공합니다. 그러나 이는 하한에 대한 정보는 포함하지 않습니다.
Theta (Θ): 알고리즘의 실행 시간이 특정 함수에 대해 **상한과 하한(Both Upper and Lower Bounds)**을 제공하는 표현입니다. 즉, 알고리즘의 실행 시간이 특정 비율로 증가한다는 것을 보장합니다. 이는 **"이 알고리즘의 실행 시간은 이 범위 내에서 증가한다"**는 정보를 제공합니다.

1. **Θ(n log₂n)**라는 표현은 Merge Sort의 실행 시간이 최악의 경우와 최선의 경우 모두에서 동일하게 성능을 유지한다는 것을 명확히 나타냅니다.
2. Θ 표기법은 알고리즘의 성능에 대한 더 정확하고 구체적인 정보를 제공합니다. 반면, O 표기법은 상한만 제공하므로, 성능이 그 이상으로 나빠질 수 있다는 여지를 남깁니다.

